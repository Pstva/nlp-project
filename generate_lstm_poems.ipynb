{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxGK8kMLynxN"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter, defaultdict\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "class PoetryLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, device, dropout=0.15):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "        self.device=device\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, X, h=None, c=None):\n",
        "        if h is None:\n",
        "            h, c = self.init_state(X.size(0))\n",
        "        out = self.embedding(X)\n",
        "        out, (h, c) = self.lstm(out, (h, c))\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        out = self.fc1(out)\n",
        "        out = out.view(-1, X.size(1), self.vocab_size)\n",
        "        out = out[:, -1]\n",
        "\n",
        "        return out, h, c\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        num_l = self.num_layers\n",
        "        hidden = torch.zeros(num_l, batch_size, self.hidden_size).to(self.device)\n",
        "        cell = torch.zeros(num_l, batch_size, self.hidden_size).to(self.device)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "\n",
        "class SimpleLSTMPoem:\n",
        "    def __init__(self, model, rhyme_model):\n",
        "        self.model = model\n",
        "        self.rhyme_model = rhyme_model\n",
        "\n",
        "    def generate_stih(self, lines_n=4, rhyme_scheme='0101', \n",
        "                      min_words_line=4, max_words_line=8):\n",
        "\n",
        "        assert lines_n == len(rhyme_scheme)\n",
        "        lines, rhyme_words = [], []\n",
        "        rhyme_scheme = reversed(list(rhyme_scheme))\n",
        "\n",
        "\n",
        "        # подсчет для каждой строки индекс рифмованной строки\n",
        "        pred_rhyme, last_rh_ind = [], {}\n",
        "        for i, rh in enumerate(rhyme_scheme):\n",
        "            if rh not in last_rh_ind:\n",
        "                last_rh_ind[rh] = i\n",
        "                pred_rhyme.append(-1)\n",
        "                continue\n",
        "            pred_rhyme.append(last_rh_ind[rh])\n",
        "            last_rh_ind[rh] = i\n",
        "        \n",
        "\n",
        "        # сначала генерируем lines_n последних слов всех строк\n",
        "        words_end = []\n",
        "        while len(words_end) < lines_n:\n",
        "            cur_word_ind = len(words_end)\n",
        "            if pred_rhyme[cur_word_ind] == -1:\n",
        "                # нет слова с которым надо рифмоваться\n",
        "                while True:\n",
        "                    word_random = vocabr[np.random.randint(0, len(vocab)-1)]\n",
        "                    next_rhyme = self.rhyme_model.give_rhyme(word_random)\n",
        "                    if next_rhyme is not None and next_rhyme in vocab:\n",
        "                        words_end.append(word_random)\n",
        "                        break\n",
        "            else:\n",
        "                word_rhyme_with = words_end[pred_rhyme[cur_word_ind]]\n",
        "                while True:\n",
        "                    new_word = self.rhyme_model.give_rhyme(word_rhyme_with)\n",
        "                    if new_word and new_word in vocab:\n",
        "                        words_end.append(new_word)\n",
        "                        break\n",
        "\n",
        "\n",
        "        # генерация строк (в обратном порядке)\n",
        "        self.model.eval()\n",
        "        seed_text = ''\n",
        "        for i in range(lines_n):\n",
        "            seed_text += \" \" + words_end[i]\n",
        "            n_words_line = np.random.randint(min_words_line, max_words_line)\n",
        "            for i in range(n_words_line-1):\n",
        "                token_list = np.ones(10, dtype=int)\n",
        "                text_token = np.array([vocab[word] for word in seed_text.split()][-10:])\n",
        "\n",
        "                token_list[:len(text_token)] = text_token\n",
        "                token_list = torch.from_numpy(token_list).unsqueeze(0).to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out, h, c = model(token_list)\n",
        "                # выбор след. слова не с максимальной вероятностью, \n",
        "                # а рандомно, основываясь на вероятностях след слова\n",
        "                p = nn.functional.softmax(out, dim=1).detach().cpu().numpy()[0]\n",
        "                idx = np.random.choice(len(out[0]), p=p)\n",
        "                new_word = vocabr[idx]\n",
        "                seed_text += \" \" + new_word\n",
        "\n",
        "            lines.append(seed_text.split()[-n_words_line:])\n",
        "\n",
        "        lines_forward = \" \\n \".join(list(reversed(list(map(lambda x: \" \".join(list(reversed(x))), lines)))))\n",
        "        return lines_forward\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxNKOFtI-UAa",
        "outputId": "4006ab82-c2bc-41bc-a7cc-2d3e3bb1212c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iTisVOm-edE"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/NLP_poems\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bacgg9aW-vug"
      },
      "outputs": [],
      "source": [
        "# загрузка словаря модели\n",
        "with open('models/lstms/lstm_vocab.json', 'r') as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "vocabr =  {v: k for k, v in vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZm8yoODzdlh"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128\n",
        "hidden_size = 512\n",
        "num_layers = 3\n",
        "device = \"cuda\"\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "model_path = \"models/lstms/35ep_128x512x3_bypoem.pth\"\n",
        "\n",
        "model = PoetryLSTM(vocab_size, embedding_dim, hidden_size, num_layers, device)\n",
        "state_dict = torch.load(model_path)\n",
        "model.load_state_dict(state_dict['model_state_dict'])\n",
        "model.to(device)\n",
        "\n",
        "rhyme_models_files =  [\"data/rhymes_2020_civil.json\", \"data/rhymes_2021_civil.json\",\n",
        "    \"data/rhymes_2020_love.json\",\t\"data/rhymes_2021_love.json\",\n",
        "    \"data/rhymes_2020_nature.json\",\t\"data/rhymes_2021_nature.json\",\n",
        "    \"data/rhymes_2020_religion.json\",\t\"data/rhymes_2021_religion.json\"]\n",
        "\n",
        "\n",
        "# загрузка одной или нескольких модели для рифмы\n",
        "from search_rhyme import RhymeSearch\n",
        "\n",
        "rhyme_model = RhymeSearch()\n",
        "rhyme_model.from_json(rhyme_models_files[0])\n",
        "for rhyme_path in rhyme_models_files[1:]:\n",
        "    new_rhyme = RhymeSearch()\n",
        "    new_rhyme.from_json(rhyme_path)\n",
        "    rhyme_model.merge_models(new_rhyme)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация"
      ],
      "metadata": {
        "id": "8LUiejUnWQ9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poems_generator = SimpleLSTMPoem(model, rhyme_model)"
      ],
      "metadata": {
        "id": "Lj_344QaJzgG"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6zaD5SQIB1F",
        "outputId": "3d2ccc5f-4fec-49f9-9d04-49959103981c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "почти всё простить вдруг не будет овен \n",
            " потерять но не парить вечность обласкала \n",
            " льёт с ароматных лишь в многоценен \n",
            " сказке гуляют зелёным зажгла \n",
            " и из старой желаемый \n",
            " багульник на наряде землю волшебный осколок рубина \n",
            " звук гонит воздуха обводный \n",
            " фотография из комплименты фонтана\n"
          ]
        }
      ],
      "source": [
        "print(poems_generator.generate_stih(lines_n=8, rhyme_scheme='01012323'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(poems_generator.generate_stih(lines_n=8, rhyme_scheme='01012323'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdB-JBQ-Wk_F",
        "outputId": "d8846c36-3dfb-43ec-8ab0-dfc38c5ee847"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "может быть и враг измотали \n",
            " увидел все желанья чтоб вновь актеры \n",
            " другим не заметив желанья петербург нить подмёрзли \n",
            " всех и стараюсь коснуться тротуары \n",
            " души подняться как помолись искренне чтоб воздать \n",
            " iv притчи гл со грешного радостью закрытых \n",
            " моя воля к тебе словно ты вычислить \n",
            " по ветвям выси прощальной чувства беспомощных\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "output_file = 'generated_poems/lstm_poems.csv'\n",
        "\n",
        "stihi = []\n",
        "for _ in range(10):\n",
        "    stihi.append(poems_generator.generate_stih(lines_n=8, rhyme_scheme='01012323'))\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "    csvwriter = csv.writer(f, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    for ind, stih in enumerate(stihi):\n",
        "        csvwriter.writerow([ind, stih])"
      ],
      "metadata": {
        "id": "wuO0WEjqWt_q"
      },
      "execution_count": 136,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "generate_poems.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}