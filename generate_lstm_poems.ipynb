{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TxGK8kMLynxN"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter, defaultdict\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "\n",
        "class PoetryLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, device, dropout=0.15):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_size = vocab_size\n",
        "        self.device=device\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, X, h=None, c=None):\n",
        "        if h is None:\n",
        "            h, c = self.init_state(X.size(0))\n",
        "        out = self.embedding(X)\n",
        "        out, (h, c) = self.lstm(out, (h, c))\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        out = self.fc1(out)\n",
        "        out = out.view(-1, X.size(1), self.vocab_size)\n",
        "        out = out[:, -1]\n",
        "\n",
        "        return out, h, c\n",
        "\n",
        "    def init_state(self, batch_size):\n",
        "        num_l = self.num_layers\n",
        "        hidden = torch.zeros(num_l, batch_size, self.hidden_size).to(self.device)\n",
        "        cell = torch.zeros(num_l, batch_size, self.hidden_size).to(self.device)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "\n",
        "class SimpleLSTMPoem:\n",
        "    def __init__(self, model, rhyme_model):\n",
        "        self.model = model\n",
        "        self.rhyme_model = rhyme_model\n",
        "\n",
        "    def generate_stih(self, lines_n=4, rhyme_scheme='0101', \n",
        "                      min_words_line=4, max_words_line=8):\n",
        "\n",
        "        assert lines_n == len(rhyme_scheme)\n",
        "        lines, rhyme_words = [], []\n",
        "        rhyme_scheme = reversed(list(rhyme_scheme))\n",
        "\n",
        "\n",
        "        # подсчет для каждой строки индекс рифмованной строки\n",
        "        pred_rhyme, last_rh_ind = [], {}\n",
        "        for i, rh in enumerate(rhyme_scheme):\n",
        "            if rh not in last_rh_ind:\n",
        "                last_rh_ind[rh] = i\n",
        "                pred_rhyme.append(-1)\n",
        "                continue\n",
        "            pred_rhyme.append(last_rh_ind[rh])\n",
        "            last_rh_ind[rh] = i\n",
        "        \n",
        "\n",
        "        # сначала генерируем lines_n последних слов всех строк\n",
        "        words_end = []\n",
        "        while len(words_end) < lines_n:\n",
        "            cur_word_ind = len(words_end)\n",
        "            if pred_rhyme[cur_word_ind] == -1:\n",
        "                # нет слова с которым надо рифмоваться\n",
        "                while True:\n",
        "                    word_random = vocabr[np.random.randint(0, len(vocab)-1)]\n",
        "                    next_rhyme = self.rhyme_model.give_rhyme(word_random)\n",
        "                    if next_rhyme is not None and next_rhyme in vocab:\n",
        "                        words_end.append(word_random)\n",
        "                        break\n",
        "            else:\n",
        "                word_rhyme_with = words_end[pred_rhyme[cur_word_ind]]\n",
        "                while True:\n",
        "                    new_word = self.rhyme_model.give_rhyme(word_rhyme_with)\n",
        "                    if new_word and new_word in vocab:\n",
        "                        words_end.append(new_word)\n",
        "                        break\n",
        "\n",
        "\n",
        "        # генерация строк (в обратном порядке)\n",
        "        self.model.eval()\n",
        "        seed_text = ''\n",
        "        for i in range(lines_n):\n",
        "            seed_text += \" \" + words_end[i]\n",
        "            n_words_line = np.random.randint(min_words_line, max_words_line)\n",
        "            for i in range(n_words_line-1):\n",
        "                token_list = np.ones(10, dtype=int)\n",
        "                text_token = np.array([vocab[word] for word in seed_text.split()][-10:])\n",
        "\n",
        "                token_list[:len(text_token)] = text_token\n",
        "                token_list = torch.from_numpy(token_list).unsqueeze(0).to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    out, h, c = model(token_list)\n",
        "                # выбор след. слова не с максимальной вероятностью, \n",
        "                # а рандомно, основываясь на вероятностях след слова\n",
        "                p = nn.functional.softmax(out, dim=1).detach().cpu().numpy()[0]\n",
        "                idx = np.random.choice(len(out[0]), p=p)\n",
        "                new_word = vocabr[idx]\n",
        "                seed_text += \" \" + new_word\n",
        "\n",
        "            lines.append(seed_text.split()[-n_words_line:])\n",
        "\n",
        "        lines_forward = \" \\n \".join(list(reversed(list(map(lambda x: \" \".join(list(reversed(x))), lines)))))\n",
        "        return lines_forward\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxNKOFtI-UAa",
        "outputId": "f0fac7c6-0a04-4161-8e7b-23fc44e795c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-iTisVOm-edE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04d5250-e458-4e67-bdbd-d3d05cb4b634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_poems\n",
            " data\t\t\t\t  models\n",
            " data_test.csv\t\t\t  navec_hudlit_v1_12B_500K_300d_100q.tar\n",
            " generated_poems\t\t  __pycache__\n",
            " generate_poems.ipynb\t\t  russian_g2p\n",
            " gpt\t\t\t\t  search_rhyme.py\n",
            "'LM evaluation.ipynb'\t\t  simple_by_poems.ipynb\n",
            " lstm0.ipynb\t\t\t  simple_lstm.ipynb\n",
            " Lstm.ipynb\t\t\t  training_models\n",
            " lstm_with_pretrained_emb.ipynb   train_lstm_with_pretrained_emb.py\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/NLP_poems\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple LSTM "
      ],
      "metadata": {
        "id": "J3IJ4SysTOE6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bacgg9aW-vug"
      },
      "outputs": [],
      "source": [
        "# загрузка словаря модели\n",
        "with open('models/lstms/lstm_vocab.json', 'r') as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "vocabr =  {v: k for k, v in vocab.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128\n",
        "hidden_size = 512\n",
        "num_layers = 3\n",
        "device = \"cuda\"\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "model_path = \"models/lstms/35ep_128x512x3_bypoem.pth\"\n",
        "\n",
        "model = PoetryLSTM(vocab_size, embedding_dim, hidden_size, num_layers, device)\n",
        "state_dict = torch.load(model_path)\n",
        "model.load_state_dict(state_dict['model_state_dict'])\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Генерация\n",
        "### без учета ударений"
      ],
      "metadata": {
        "id": "8LUiejUnWQ9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rhyme_models_files =  [\"data/rhymes_2020_civil.json\", \"data/rhymes_2021_civil.json\",\n",
        "    \"data/rhymes_2020_love.json\",\t\"data/rhymes_2021_love.json\",\n",
        "    \"data/rhymes_2020_nature.json\",\t\"data/rhymes_2021_nature.json\",\n",
        "    \"data/rhymes_2020_religion.json\",\t\"data/rhymes_2021_religion.json\"]\n",
        "\n",
        "\n",
        "# загрузка одной или нескольких модели для рифмы\n",
        "from search_rhyme import RhymeSearch\n",
        "\n",
        "rhyme_model = RhymeSearch()\n",
        "rhyme_model.from_json(rhyme_models_files[0])\n",
        "for rhyme_path in rhyme_models_files[1:]:\n",
        "    new_rhyme = RhymeSearch()\n",
        "    new_rhyme.from_json(rhyme_path)\n",
        "    rhyme_model.merge_models(new_rhyme)"
      ],
      "metadata": {
        "id": "FkJKEBhTINGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poems_generator = SimpleLSTMPoem(model, rhyme_model)"
      ],
      "metadata": {
        "id": "Lj_344QaJzgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6zaD5SQIB1F",
        "outputId": "3d2ccc5f-4fec-49f9-9d04-49959103981c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "почти всё простить вдруг не будет овен \n",
            " потерять но не парить вечность обласкала \n",
            " льёт с ароматных лишь в многоценен \n",
            " сказке гуляют зелёным зажгла \n",
            " и из старой желаемый \n",
            " багульник на наряде землю волшебный осколок рубина \n",
            " звук гонит воздуха обводный \n",
            " фотография из комплименты фонтана\n"
          ]
        }
      ],
      "source": [
        "print(poems_generator.generate_stih(lines_n=8, rhyme_scheme='01012323'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(poems_generator.generate_stih(lines_n=8, rhyme_scheme='01012323'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdB-JBQ-Wk_F",
        "outputId": "d8846c36-3dfb-43ec-8ab0-dfc38c5ee847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "может быть и враг измотали \n",
            " увидел все желанья чтоб вновь актеры \n",
            " другим не заметив желанья петербург нить подмёрзли \n",
            " всех и стараюсь коснуться тротуары \n",
            " души подняться как помолись искренне чтоб воздать \n",
            " iv притчи гл со грешного радостью закрытых \n",
            " моя воля к тебе словно ты вычислить \n",
            " по ветвям выси прощальной чувства беспомощных\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "output_file = 'generated_poems/lstm_poems.csv'\n",
        "\n",
        "stihi = []\n",
        "for _ in range(10):\n",
        "    stihi.append(poems_generator.generate_stih(lines_n=8, rhyme_scheme='01012323'))\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "    csvwriter = csv.writer(f, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    for ind, stih in enumerate(stihi):\n",
        "        csvwriter.writerow([ind, stih])"
      ],
      "metadata": {
        "id": "wuO0WEjqWt_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### С ударениями"
      ],
      "metadata": {
        "id": "9e79w-kfID0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dawg"
      ],
      "metadata": {
        "id": "e-PdL722KA0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rhyme_models_files =  [\"data/rhymes_acc_2020_civil.json\", \"data/rhymes_acc_2021_civil.json\",\n",
        "    \"data/rhymes_acc_2020_love.json\",\t\"data/rhymes_acc_2021_love.json\",\n",
        "    \"data/rhymes_acc_2020_nature.json\",\t\"data/rhymes_acc_2021_nature.json\",\n",
        "    \"data/rhymes_acc_2020_religion.json\",\t\"data/rhymes_acc_2021_religion.json\"]\n",
        "\n",
        "\n",
        "# загрузка одной или нескольких модели для рифмы\n",
        "from search_rhyme import RhymeSearch\n",
        "\n",
        "rhyme_model = RhymeSearch(with_accent=True)\n",
        "rhyme_model.from_json(rhyme_models_files[0])\n",
        "for rhyme_path in rhyme_models_files[1:]:\n",
        "    new_rhyme = RhymeSearch()\n",
        "    new_rhyme.from_json(rhyme_path)\n",
        "    rhyme_model.merge_models(new_rhyme)\n",
        "\n",
        "poems_generator = SimpleLSTMPoem(model, rhyme_model)"
      ],
      "metadata": {
        "id": "Gkgo1QmiIOyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(poems_generator.generate_stih(lines_n=4, rhyme_scheme='0101'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu6aWEYTIm4s",
        "outputId": "fdee4b20-4263-4092-9449-4ae40f5f6bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "иуды ещё пошло осталась по степным звездам \n",
            " и тайно янв для лучей \n",
            " под днем та выдам \n",
            " нечисть так каждому лихих зад автор врачей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import tqdm\n",
        "output_file = 'generated_poems/lstm_acc_poems.csv'\n",
        "\n",
        "stihi = []\n",
        "for _ in tqdm.tqdm(range(200)):\n",
        "    stihi.append(poems_generator.generate_stih(lines_n=4, rhyme_scheme='0101'))\n",
        "\n",
        "with open(output_file, 'a') as f:\n",
        "    csvwriter = csv.writer(f, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    for ind, stih in enumerate(stihi):\n",
        "        csvwriter.writerow([ind, stih])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0i6fKKrIVGL",
        "outputId": "48dac071-d18e-4b9a-a6ef-a307ea899643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 196/200 [12:41<00:16,  4.22s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM с предобученными эмбеддингами, с ударениями"
      ],
      "metadata": {
        "id": "OuhXMUlOTSnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dawg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhA0GIWBTZbE",
        "outputId": "77b6db64-2fee-4be3-bfbb-4eb8e78fd400"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dawg\n",
            "  Downloading DAWG-0.8.0.tar.gz (371 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 371 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: dawg\n",
            "  Building wheel for dawg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dawg: filename=DAWG-0.8.0-cp37-cp37m-linux_x86_64.whl size=863056 sha256=01734b8e193e96eeaeb6036028ab793bf5433a56e6957aa39b81e168c7b8f04b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/51/a4/2de41ff197786537075027c27b479a38da92f50abc86634445\n",
            "Successfully built dawg\n",
            "Installing collected packages: dawg\n",
            "Successfully installed dawg-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузка словаря модели\n",
        "with open('models/lstms/lstm_vocab_emb.json', 'r') as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "vocabr =  {v: k for k, v in vocab.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "hidden_size = 512\n",
        "num_layers = 3\n",
        "device = \"cuda\"\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "model_path = \"models/lstms/30ep_300x512x3_bypoem_emb.pth\"\n",
        "\n",
        "model = PoetryLSTM(vocab_size, embedding_dim, hidden_size, num_layers, device)\n",
        "state_dict = torch.load(model_path)\n",
        "model.load_state_dict(state_dict['model_state_dict'])\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm8DmCalT8Zn",
        "outputId": "489bbb09-c320-433a-c560-b67ef091cd13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoetryLSTM(\n",
              "  (embedding): Embedding(136619, 300)\n",
              "  (lstm): LSTM(300, 512, num_layers=3, batch_first=True, dropout=0.15)\n",
              "  (fc1): Linear(in_features=512, out_features=136619, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rhyme_models_files =  [\"data/rhymes_acc_2020_civil.json\", \"data/rhymes_acc_2021_civil.json\",\n",
        "    \"data/rhymes_acc_2020_love.json\",\t\"data/rhymes_acc_2021_love.json\",\n",
        "    \"data/rhymes_acc_2020_nature.json\",\t\"data/rhymes_acc_2021_nature.json\",\n",
        "    \"data/rhymes_acc_2020_religion.json\",\t\"data/rhymes_acc_2021_religion.json\"]\n",
        "\n",
        "\n",
        "# загрузка одной или нескольких модели для рифмы\n",
        "from search_rhyme import RhymeSearch\n",
        "\n",
        "rhyme_model = RhymeSearch(with_accent=True)\n",
        "rhyme_model.from_json(rhyme_models_files[0])\n",
        "for rhyme_path in rhyme_models_files[1:]:\n",
        "    new_rhyme = RhymeSearch()\n",
        "    new_rhyme.from_json(rhyme_path)\n",
        "    rhyme_model.merge_models(new_rhyme)\n",
        "\n",
        "poems_generator = SimpleLSTMPoem(model, rhyme_model)"
      ],
      "metadata": {
        "id": "-GzKM9JwTZ70"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(poems_generator.generate_stih(lines_n=4, rhyme_scheme='0101'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw3-RQUOTdZQ",
        "outputId": "f49210c6-3354-4e7d-9480-9088aacbf4f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "идут как мотыльки прятались бандер \n",
            " повсюду круги моя strip \n",
            " ласки нам места да едер \n",
            " нашей русской верой в христа душа grip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import tqdm\n",
        "output_file = 'generated_poems/lstm_acc_emb_poems.csv'\n",
        "\n",
        "stihi = []\n",
        "for _ in tqdm.tqdm(range(400)):\n",
        "    stihi.append(poems_generator.generate_stih(lines_n=4, rhyme_scheme='0101'))\n",
        "\n",
        "with open(output_file, 'a') as f:\n",
        "    csvwriter = csv.writer(f, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "    for ind, stih in enumerate(stihi):\n",
        "        csvwriter.writerow([ind, stih])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0wJqymJTeOb",
        "outputId": "6e3b6472-c7ac-4909-c513-fab9943991b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [25:33<00:00,  3.83s/it]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "generate_poems.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}